{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f463ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400645e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = os.getenv(\"RESNET_MODEL_FOLDER\")\n",
    "print(model_folder)\n",
    "\n",
    "target_class = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e80b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nadf.data.adversarial import load_or_create_dataset\n",
    "\n",
    "dataset = load_or_create_dataset(\n",
    "    folder=model_folder,\n",
    "    target_class=target_class,\n",
    "    num_attacks_eps_coef=[(4, 0.25), (2, 0.5), (3, 1.0), (1, 2.0)],\n",
    "    recreate=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b4ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.keys())\n",
    "print(dataset[\"y\"][\"train\"].unique())\n",
    "print(dataset[\"y\"][\"val\"].unique())\n",
    "print(dataset[\"y\"][\"test\"].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e23fcc",
   "metadata": {},
   "source": [
    "## Visualize Misclassification trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f463135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make heatmap out of csv file\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/results/prediction_distribution/prediction_distribution_target_-1_split_test.csv\")\n",
    "\n",
    "# make heatmap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# every row should be shaded according to how big of a part of the row sum it is \n",
    "# Set actual_class as index\n",
    "df_indexed = df.set_index('actual_class')\n",
    "\n",
    "# Normalize each row by dividing by row sum (so each row sums to 1)\n",
    "df_normalized = df_indexed.div(df_indexed.sum(axis=1), axis=0)\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df_normalized, annot=True, fmt='.2f', cmap='Greens', \n",
    "            cbar_kws={'label': 'Proportion'}, \n",
    "            xticklabels=[f'Pred {i}' for i in range(10)],\n",
    "            yticklabels=[f'Actual {i}' for i in range(10)])\n",
    "plt.title('Prediction Distribution Heatmap (Row Normalized)')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Actual Class')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"data/results/prediction_distribution/prediction_distribution_target_-1_split_test.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c08ffda",
   "metadata": {},
   "source": [
    "## Load regression dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765d85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import dotenv\n",
    "from argparse import Namespace\n",
    "from nadf.training.pipeline import train_probe_model\n",
    "from typing import Dict, Any\n",
    "import os, glob, torch\n",
    "from nadf.training.pipeline import load_probe_model\n",
    "\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "model_folder = os.getenv(\"RESNET_MODEL_FOLDER\")\n",
    "target_class = -1\n",
    "print(model_folder)\n",
    "\n",
    "regression_dataset_path = os.path.join(model_folder, \"adversarial_examples\", str(target_class), \"regression_dataset.pt\")\n",
    "regression_datasets = torch.load(regression_dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4682a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "\n",
    "# Check for target distances = 0\n",
    "exact_zeros = regression_datasets[\"train\"][1] == 0\n",
    "num_exact_zeros = (regression_datasets[\"train\"][1] == 0).sum()\n",
    "\n",
    "num_exact_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6ad4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anchors, distances, labels, upweights\n",
    "regression_datasets[\"train\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b588db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize anchors using t-sne\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "# Choose label type: \"class\" for class labels from regression_datasets[\"train\"][2], \n",
    "#                    \"clean_adversarial\" for clean/adversarial based on distances\n",
    "label_type = [\"clean_adversarial\", \"class\"][1]  # Change to \"class\" to use class labels\n",
    "\n",
    "# Get the anchor points from the regression dataset\n",
    "anchors = regression_datasets[\"train\"][0]  # Shape: (N, feature_dim)\n",
    "distances = regression_datasets[\"train\"][1]  # Shape: (N,)\n",
    "class_labels = regression_datasets[\"train\"][2]  # Shape: (N,) - class labels\n",
    "\n",
    "# Convert to numpy for sklearn (detach to remove gradient tracking)\n",
    "anchors_np = anchors.cpu().detach().numpy()\n",
    "distances_np = distances.cpu().detach().numpy()\n",
    "class_labels_np = class_labels.cpu().detach().numpy()\n",
    "\n",
    "# Create clean/adversarial labels: \"clean\" if distance == 0, \"adversarial\" if distance > 0\n",
    "clean_adv_labels = np.where(distances_np == 0, \"clean\", \"adversarial\")\n",
    "\n",
    "# Select labels based on label_type parameter\n",
    "if label_type == \"class\":\n",
    "    visualization_labels = class_labels_np\n",
    "elif label_type == \"clean_adversarial\":\n",
    "    visualization_labels = clean_adv_labels\n",
    "else:\n",
    "    raise ValueError(f\"label_type must be 'class' or 'clean_adversarial', got '{label_type}'\")\n",
    "\n",
    "# Subsample for faster t-SNE computation\n",
    "# Set max_samples to None to use all data, or specify a number (e.g., 5000)\n",
    "max_samples = 5000  # Adjust this based on your dataset size and computational resources\n",
    "\n",
    "if max_samples is not None and len(anchors_np) > max_samples:\n",
    "    print(f\"Subsampling from {len(anchors_np)} to {max_samples} samples...\")\n",
    "    \n",
    "    # Stratified subsampling based on visualization labels\n",
    "    if label_type == \"clean_adversarial\":\n",
    "        # Stratified by clean/adversarial\n",
    "        clean_indices = np.where(clean_adv_labels == \"clean\")[0]\n",
    "        adversarial_indices = np.where(clean_adv_labels == \"adversarial\")[0]\n",
    "        \n",
    "        clean_proportion = len(clean_indices) / len(clean_adv_labels)\n",
    "        n_clean_samples = int(max_samples * clean_proportion)\n",
    "        n_adversarial_samples = max_samples - n_clean_samples\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        sampled_clean_indices = np.random.choice(clean_indices, size=min(n_clean_samples, len(clean_indices)), replace=False)\n",
    "        sampled_adv_indices = np.random.choice(adversarial_indices, size=min(n_adversarial_samples, len(adversarial_indices)), replace=False)\n",
    "        \n",
    "        sampled_indices = np.concatenate([sampled_clean_indices, sampled_adv_indices])\n",
    "        print(f\"  Clean samples: {len(sampled_clean_indices)}\")\n",
    "        print(f\"  Adversarial samples: {len(sampled_adv_indices)}\")\n",
    "    else:\n",
    "        # Stratified by class labels\n",
    "        unique_classes = np.unique(class_labels_np)\n",
    "        sampled_indices_list = []\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        samples_per_class = max_samples // len(unique_classes)\n",
    "        remainder = max_samples % len(unique_classes)\n",
    "        \n",
    "        for i, cls in enumerate(unique_classes):\n",
    "            class_indices = np.where(class_labels_np == cls)[0]\n",
    "            n_samples = samples_per_class + (1 if i < remainder else 0)\n",
    "            n_samples = min(n_samples, len(class_indices))\n",
    "            sampled_class_indices = np.random.choice(class_indices, size=n_samples, replace=False)\n",
    "            sampled_indices_list.append(sampled_class_indices)\n",
    "            print(f\"  Class {cls} samples: {n_samples}\")\n",
    "        \n",
    "        sampled_indices = np.concatenate(sampled_indices_list)\n",
    "    \n",
    "    np.random.shuffle(sampled_indices)  # Shuffle for better visualization\n",
    "    \n",
    "    # Subsample the data\n",
    "    anchors_np = anchors_np[sampled_indices]\n",
    "    class_labels_np = class_labels_np[sampled_indices]\n",
    "    clean_adv_labels = clean_adv_labels[sampled_indices]\n",
    "    visualization_labels = visualization_labels[sampled_indices]\n",
    "    distances_np = distances_np[sampled_indices]\n",
    "\n",
    "# Apply t-SNE\n",
    "print(\"Applying t-SNE...\")\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "anchors_2d = tsne.fit_transform(anchors_np)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "if label_type == \"clean_adversarial\":\n",
    "    # Visualize by clean/adversarial\n",
    "    for label_val in [\"clean\", \"adversarial\"]:\n",
    "        mask = visualization_labels == label_val\n",
    "        plt.scatter(anchors_2d[mask, 0], anchors_2d[mask, 1], \n",
    "                    label=label_val, alpha=0.6, s=10)\n",
    "    plt.title(\"t-SNE Visualization of Anchors (Clean vs Adversarial)\")\n",
    "else:\n",
    "    # Visualize by class labels (0-9)\n",
    "    unique_labels = np.unique(visualization_labels)\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))\n",
    "    for i, cls in enumerate(unique_labels):\n",
    "        mask = visualization_labels == cls\n",
    "        plt.scatter(anchors_2d[mask, 0], anchors_2d[mask, 1], \n",
    "                    label=f\"Class {cls}\", alpha=0.6, s=10, c=[colors[i]])\n",
    "    plt.title(\"t-SNE Visualization of Anchors by Class\")\n",
    "\n",
    "plt.xlabel(\"t-SNE Component 1\")\n",
    "plt.ylabel(\"t-SNE Component 2\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"data/results/t-sne_visualization_anchors_target_{target_class}_{label_type}.pdf\")\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(f\"\\nFinal dataset size: {len(visualization_labels)}\")\n",
    "if label_type == \"clean_adversarial\":\n",
    "    num_clean = (visualization_labels == \"clean\").sum()\n",
    "    num_adversarial = (visualization_labels == \"adversarial\").sum()\n",
    "    print(f\"Number of clean samples: {num_clean}\")\n",
    "    print(f\"Number of adversarial samples: {num_adversarial}\")\n",
    "print(f\"Class labels (unique): {np.unique(class_labels_np)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b0bbb9",
   "metadata": {},
   "source": [
    "# Do stronger attacks lie farther away from the manifold ? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv)",
   "language": "python",
   "name": "uv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
